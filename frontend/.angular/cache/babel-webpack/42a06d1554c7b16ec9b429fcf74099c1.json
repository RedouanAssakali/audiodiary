{"ast":null,"code":"import _defaults from \"lodash.defaultsdeep\";\nimport h from \"virtual-dom/h\";\nimport diff from \"virtual-dom/diff\";\nimport patch from \"virtual-dom/patch\";\nimport InlineWorker from \"inline-worker\";\nimport { pixelsToSeconds } from \"./utils/conversions\";\nimport LoaderFactory from \"./track/loader/LoaderFactory\";\nimport ScrollHook from \"./render/ScrollHook\";\nimport TimeScale from \"./TimeScale\";\nimport Track from \"./Track\";\nimport Playout from \"./Playout\";\nimport AnnotationList from \"./annotation/AnnotationList\";\nimport RecorderWorkerFunction from \"./utils/recorderWorker\";\nimport ExportWavWorkerFunction from \"./utils/exportWavWorker\";\nexport default class {\n  constructor() {\n    this.tracks = [];\n    this.soloedTracks = [];\n    this.mutedTracks = [];\n    this.collapsedTracks = [];\n    this.playoutPromises = [];\n    this.cursor = 0;\n    this.playbackSeconds = 0;\n    this.duration = 0;\n    this.scrollLeft = 0;\n    this.scrollTimer = undefined;\n    this.showTimescale = false; // whether a user is scrolling the waveform\n\n    this.isScrolling = false;\n    this.fadeType = \"logarithmic\";\n    this.masterGain = 1;\n    this.annotations = [];\n    this.durationFormat = \"hh:mm:ss.uuu\";\n    this.isAutomaticScroll = false;\n    this.resetDrawTimer = undefined;\n  } // TODO extract into a plugin\n\n\n  initExporter() {\n    this.exportWorker = new InlineWorker(ExportWavWorkerFunction);\n  } // TODO extract into a plugin\n\n\n  initRecorder(stream) {\n    this.mediaRecorder = new MediaRecorder(stream);\n\n    this.mediaRecorder.onstart = () => {\n      const track = new Track();\n      track.setName(\"Recording\");\n      track.setEnabledStates();\n      track.setEventEmitter(this.ee);\n      this.recordingTrack = track;\n      this.tracks.push(track);\n      this.chunks = [];\n      this.working = false;\n    };\n\n    this.mediaRecorder.ondataavailable = e => {\n      this.chunks.push(e.data); // throttle peaks calculation\n\n      if (!this.working) {\n        const recording = new Blob(this.chunks, {\n          type: \"audio/ogg; codecs=opus\"\n        });\n        const loader = LoaderFactory.createLoader(recording, this.ac);\n        loader.load().then(audioBuffer => {\n          // ask web worker for peaks.\n          this.recorderWorker.postMessage({\n            samples: audioBuffer.getChannelData(0),\n            samplesPerPixel: this.samplesPerPixel\n          });\n          this.recordingTrack.setCues(0, audioBuffer.duration);\n          this.recordingTrack.setBuffer(audioBuffer);\n          this.recordingTrack.setPlayout(new Playout(this.ac, audioBuffer));\n          this.adjustDuration();\n        }).catch(() => {\n          this.working = false;\n        });\n        this.working = true;\n      }\n    };\n\n    this.mediaRecorder.onstop = () => {\n      this.chunks = [];\n      this.working = false;\n    };\n\n    this.recorderWorker = new InlineWorker(RecorderWorkerFunction); // use a worker for calculating recording peaks.\n\n    this.recorderWorker.onmessage = e => {\n      this.recordingTrack.setPeaks(e.data);\n      this.working = false;\n      this.drawRequest();\n    };\n  }\n\n  setShowTimeScale(show) {\n    this.showTimescale = show;\n  }\n\n  setMono(mono) {\n    this.mono = mono;\n  }\n\n  setExclSolo(exclSolo) {\n    this.exclSolo = exclSolo;\n  }\n\n  setSeekStyle(style) {\n    this.seekStyle = style;\n  }\n\n  getSeekStyle() {\n    return this.seekStyle;\n  }\n\n  setSampleRate(sampleRate) {\n    this.sampleRate = sampleRate;\n  }\n\n  setSamplesPerPixel(samplesPerPixel) {\n    this.samplesPerPixel = samplesPerPixel;\n  }\n\n  setAudioContext(ac) {\n    this.ac = ac;\n  }\n\n  setControlOptions(controlOptions) {\n    this.controls = controlOptions;\n  }\n\n  setWaveHeight(height) {\n    this.waveHeight = height;\n  }\n\n  setCollapsedWaveHeight(height) {\n    this.collapsedWaveHeight = height;\n  }\n\n  setColors(colors) {\n    this.colors = colors;\n  }\n\n  setBarWidth(width) {\n    this.barWidth = width;\n  }\n\n  setBarGap(width) {\n    this.barGap = width;\n  }\n\n  setAnnotations(config) {\n    const controlWidth = this.controls.show ? this.controls.width : 0;\n    this.annotationList = new AnnotationList(this, config.annotations, config.controls, config.editable, config.linkEndpoints, config.isContinuousPlay, controlWidth);\n  }\n\n  setEventEmitter(ee) {\n    this.ee = ee;\n  }\n\n  getEventEmitter() {\n    return this.ee;\n  }\n\n  setUpEventEmitter() {\n    const ee = this.ee;\n    ee.on(\"automaticscroll\", val => {\n      this.isAutomaticScroll = val;\n    });\n    ee.on(\"durationformat\", format => {\n      this.durationFormat = format;\n      this.drawRequest();\n    });\n    ee.on(\"select\", (start, end, track) => {\n      if (this.isPlaying()) {\n        this.lastSeeked = start;\n        this.pausedAt = undefined;\n        this.restartPlayFrom(start);\n      } else {\n        // reset if it was paused.\n        this.seek(start, end, track);\n        this.ee.emit(\"timeupdate\", start);\n        this.drawRequest();\n      }\n    });\n    ee.on(\"startaudiorendering\", type => {\n      this.startOfflineRender(type);\n    });\n    ee.on(\"statechange\", state => {\n      this.setState(state);\n      this.drawRequest();\n    });\n    ee.on(\"shift\", (deltaTime, track) => {\n      track.setStartTime(track.getStartTime() + deltaTime);\n      this.adjustDuration();\n      this.drawRequest();\n    });\n    ee.on(\"record\", () => {\n      this.record();\n    });\n    ee.on(\"play\", (start, end) => {\n      this.play(start, end);\n    });\n    ee.on(\"pause\", () => {\n      this.pause();\n    });\n    ee.on(\"stop\", () => {\n      this.stop();\n    });\n    ee.on(\"rewind\", () => {\n      this.rewind();\n    });\n    ee.on(\"fastforward\", () => {\n      this.fastForward();\n    });\n    ee.on(\"clear\", () => {\n      this.clear().then(() => {\n        this.drawRequest();\n      });\n    });\n    ee.on(\"solo\", track => {\n      this.soloTrack(track);\n      this.adjustTrackPlayout();\n      this.drawRequest();\n    });\n    ee.on(\"mute\", track => {\n      this.muteTrack(track);\n      this.adjustTrackPlayout();\n      this.drawRequest();\n    });\n    ee.on(\"removeTrack\", track => {\n      this.removeTrack(track);\n      this.adjustTrackPlayout();\n      this.drawRequest();\n    });\n    ee.on(\"changeTrackView\", (track, opts) => {\n      this.collapseTrack(track, opts);\n      this.drawRequest();\n    });\n    ee.on(\"volumechange\", (volume, track) => {\n      track.setGainLevel(volume / 100);\n      this.drawRequest();\n    });\n    ee.on(\"mastervolumechange\", volume => {\n      this.masterGain = volume / 100;\n      this.tracks.forEach(track => {\n        track.setMasterGainLevel(this.masterGain);\n      });\n    });\n    ee.on(\"fadein\", (duration, track) => {\n      track.setFadeIn(duration, this.fadeType);\n      this.drawRequest();\n    });\n    ee.on(\"fadeout\", (duration, track) => {\n      track.setFadeOut(duration, this.fadeType);\n      this.drawRequest();\n    });\n    ee.on(\"stereopan\", (panvalue, track) => {\n      track.setStereoPanValue(panvalue);\n      this.drawRequest();\n    });\n    ee.on(\"fadetype\", type => {\n      this.fadeType = type;\n    });\n    ee.on(\"newtrack\", file => {\n      this.load([{\n        src: file,\n        name: file.name\n      }]);\n    });\n    ee.on(\"trim\", () => {\n      const track = this.getActiveTrack();\n      const timeSelection = this.getTimeSelection();\n      track.trim(timeSelection.start, timeSelection.end);\n      track.calculatePeaks(this.samplesPerPixel, this.sampleRate);\n      this.setTimeSelection(0, 0);\n      this.drawRequest();\n    });\n    ee.on(\"zoomin\", () => {\n      const zoomIndex = Math.max(0, this.zoomIndex - 1);\n      const zoom = this.zoomLevels[zoomIndex];\n\n      if (zoom !== this.samplesPerPixel) {\n        this.setZoom(zoom);\n        this.drawRequest();\n      }\n    });\n    ee.on(\"zoomout\", () => {\n      const zoomIndex = Math.min(this.zoomLevels.length - 1, this.zoomIndex + 1);\n      const zoom = this.zoomLevels[zoomIndex];\n\n      if (zoom !== this.samplesPerPixel) {\n        this.setZoom(zoom);\n        this.drawRequest();\n      }\n    });\n    ee.on(\"scroll\", () => {\n      this.isScrolling = true;\n      this.drawRequest();\n      clearTimeout(this.scrollTimer);\n      this.scrollTimer = setTimeout(() => {\n        this.isScrolling = false;\n      }, 200);\n    });\n  }\n\n  load(trackList) {\n    const loadPromises = trackList.map(trackInfo => {\n      const loader = LoaderFactory.createLoader(trackInfo.src, this.ac, this.ee);\n      return loader.load();\n    });\n    return Promise.all(loadPromises).then(audioBuffers => {\n      this.ee.emit(\"audiosourcesloaded\");\n      const tracks = audioBuffers.map((audioBuffer, index) => {\n        const info = trackList[index];\n        const name = info.name || \"Untitled\";\n        const start = info.start || 0;\n        const states = info.states || {};\n        const fadeIn = info.fadeIn;\n        const fadeOut = info.fadeOut;\n        const cueIn = info.cuein || 0;\n        const cueOut = info.cueout || audioBuffer.duration;\n        const gain = info.gain || 1;\n        const muted = info.muted || false;\n        const soloed = info.soloed || false;\n        const selection = info.selected;\n        const peaks = info.peaks || {\n          type: \"WebAudio\",\n          mono: this.mono\n        };\n        const customClass = info.customClass || undefined;\n        const waveOutlineColor = info.waveOutlineColor || undefined;\n        const stereoPan = info.stereoPan || 0; // webaudio specific playout for now.\n\n        const playout = new Playout(this.ac, audioBuffer);\n        const track = new Track();\n        track.src = info.src;\n        track.setBuffer(audioBuffer);\n        track.setName(name);\n        track.setEventEmitter(this.ee);\n        track.setEnabledStates(states);\n        track.setCues(cueIn, cueOut);\n        track.setCustomClass(customClass);\n        track.setWaveOutlineColor(waveOutlineColor);\n\n        if (fadeIn !== undefined) {\n          track.setFadeIn(fadeIn.duration, fadeIn.shape);\n        }\n\n        if (fadeOut !== undefined) {\n          track.setFadeOut(fadeOut.duration, fadeOut.shape);\n        }\n\n        if (selection !== undefined) {\n          this.setActiveTrack(track);\n          this.setTimeSelection(selection.start, selection.end);\n        }\n\n        if (peaks !== undefined) {\n          track.setPeakData(peaks);\n        }\n\n        track.setState(this.getState());\n        track.setStartTime(start);\n        track.setPlayout(playout);\n        track.setGainLevel(gain);\n        track.setStereoPanValue(stereoPan);\n\n        if (muted) {\n          this.muteTrack(track);\n        }\n\n        if (soloed) {\n          this.soloTrack(track);\n        } // extract peaks with AudioContext for now.\n\n\n        track.calculatePeaks(this.samplesPerPixel, this.sampleRate);\n        return track;\n      });\n      this.tracks = this.tracks.concat(tracks);\n      this.adjustDuration();\n      this.draw(this.render());\n      this.ee.emit(\"audiosourcesrendered\");\n    }).catch(e => {\n      this.ee.emit(\"audiosourceserror\", e);\n    });\n  }\n  /*\n    track instance of Track.\n  */\n\n\n  setActiveTrack(track) {\n    this.activeTrack = track;\n  }\n\n  getActiveTrack() {\n    return this.activeTrack;\n  }\n\n  isSegmentSelection() {\n    return this.timeSelection.start !== this.timeSelection.end;\n  }\n  /*\n    start, end in seconds.\n  */\n\n\n  setTimeSelection(start = 0, end) {\n    this.timeSelection = {\n      start,\n      end: end === undefined ? start : end\n    };\n    this.cursor = start;\n  }\n\n  startOfflineRender(type) {\n    if (this.isRendering) {\n      return;\n    }\n\n    this.isRendering = true;\n    this.offlineAudioContext = new OfflineAudioContext(2, 44100 * this.duration, 44100);\n    const currentTime = this.offlineAudioContext.currentTime;\n    this.tracks.forEach(track => {\n      track.setOfflinePlayout(new Playout(this.offlineAudioContext, track.buffer));\n      track.schedulePlay(currentTime, 0, 0, {\n        shouldPlay: this.shouldTrackPlay(track),\n        masterGain: 1,\n        isOffline: true\n      });\n    });\n    /*\n      TODO cleanup of different audio playouts handling.\n    */\n\n    this.offlineAudioContext.startRendering().then(audioBuffer => {\n      if (type === \"buffer\") {\n        this.ee.emit(\"audiorenderingfinished\", type, audioBuffer);\n        this.isRendering = false;\n        return;\n      }\n\n      if (type === \"wav\") {\n        this.exportWorker.postMessage({\n          command: \"init\",\n          config: {\n            sampleRate: 44100\n          }\n        }); // callback for `exportWAV`\n\n        this.exportWorker.onmessage = e => {\n          this.ee.emit(\"audiorenderingfinished\", type, e.data);\n          this.isRendering = false; // clear out the buffer for next renderings.\n\n          this.exportWorker.postMessage({\n            command: \"clear\"\n          });\n        }; // send the channel data from our buffer to the worker\n\n\n        this.exportWorker.postMessage({\n          command: \"record\",\n          buffer: [audioBuffer.getChannelData(0), audioBuffer.getChannelData(1)]\n        }); // ask the worker for a WAV\n\n        this.exportWorker.postMessage({\n          command: \"exportWAV\",\n          type: \"audio/wav\"\n        });\n      }\n    }).catch(e => {\n      throw e;\n    });\n  }\n\n  getTimeSelection() {\n    return this.timeSelection;\n  }\n\n  setState(state) {\n    this.state = state;\n    this.tracks.forEach(track => {\n      track.setState(state);\n    });\n  }\n\n  getState() {\n    return this.state;\n  }\n\n  setZoomIndex(index) {\n    this.zoomIndex = index;\n  }\n\n  setZoomLevels(levels) {\n    this.zoomLevels = levels;\n  }\n\n  setZoom(zoom) {\n    this.samplesPerPixel = zoom;\n    this.zoomIndex = this.zoomLevels.indexOf(zoom);\n    this.tracks.forEach(track => {\n      track.calculatePeaks(zoom, this.sampleRate);\n    });\n  }\n\n  muteTrack(track) {\n    const index = this.mutedTracks.indexOf(track);\n\n    if (index > -1) {\n      this.mutedTracks.splice(index, 1);\n    } else {\n      this.mutedTracks.push(track);\n    }\n  }\n\n  soloTrack(track) {\n    const index = this.soloedTracks.indexOf(track);\n\n    if (index > -1) {\n      this.soloedTracks.splice(index, 1);\n    } else if (this.exclSolo) {\n      this.soloedTracks = [track];\n    } else {\n      this.soloedTracks.push(track);\n    }\n  }\n\n  collapseTrack(track, opts) {\n    if (opts.collapsed) {\n      this.collapsedTracks.push(track);\n    } else {\n      const index = this.collapsedTracks.indexOf(track);\n\n      if (index > -1) {\n        this.collapsedTracks.splice(index, 1);\n      }\n    }\n  }\n\n  removeTrack(track) {\n    if (track.isPlaying()) {\n      track.scheduleStop();\n    }\n\n    const trackLists = [this.mutedTracks, this.soloedTracks, this.collapsedTracks, this.tracks];\n    trackLists.forEach(list => {\n      const index = list.indexOf(track);\n\n      if (index > -1) {\n        list.splice(index, 1);\n      }\n    });\n  }\n\n  adjustTrackPlayout() {\n    this.tracks.forEach(track => {\n      track.setShouldPlay(this.shouldTrackPlay(track));\n    });\n  }\n\n  adjustDuration() {\n    this.duration = this.tracks.reduce((duration, track) => Math.max(duration, track.getEndTime()), 0);\n  }\n\n  shouldTrackPlay(track) {\n    let shouldPlay; // if there are solo tracks, only they should play.\n\n    if (this.soloedTracks.length > 0) {\n      shouldPlay = false;\n\n      if (this.soloedTracks.indexOf(track) > -1) {\n        shouldPlay = true;\n      }\n    } else {\n      // play all tracks except any muted tracks.\n      shouldPlay = true;\n\n      if (this.mutedTracks.indexOf(track) > -1) {\n        shouldPlay = false;\n      }\n    }\n\n    return shouldPlay;\n  }\n\n  isPlaying() {\n    return this.tracks.reduce((isPlaying, track) => isPlaying || track.isPlaying(), false);\n  }\n  /*\n   *   returns the current point of time in the playlist in seconds.\n   */\n\n\n  getCurrentTime() {\n    const cursorPos = this.lastSeeked || this.pausedAt || this.cursor;\n    return cursorPos + this.getElapsedTime();\n  }\n\n  getElapsedTime() {\n    return this.ac.currentTime - this.lastPlay;\n  }\n\n  setMasterGain(gain) {\n    this.ee.emit(\"mastervolumechange\", gain);\n  }\n\n  restartPlayFrom(start, end) {\n    this.stopAnimation();\n    this.tracks.forEach(editor => {\n      editor.scheduleStop();\n    });\n    return Promise.all(this.playoutPromises).then(this.play.bind(this, start, end));\n  }\n\n  play(startTime, endTime) {\n    clearTimeout(this.resetDrawTimer);\n    const currentTime = this.ac.currentTime;\n    const selected = this.getTimeSelection();\n    const playoutPromises = [];\n    const start = startTime || this.pausedAt || this.cursor;\n    let end = endTime;\n\n    if (!end && selected.end !== selected.start && selected.end > start) {\n      end = selected.end;\n    }\n\n    if (this.isPlaying()) {\n      return this.restartPlayFrom(start, end);\n    }\n\n    this.tracks.forEach(track => {\n      track.setState(\"cursor\");\n      playoutPromises.push(track.schedulePlay(currentTime, start, end, {\n        shouldPlay: this.shouldTrackPlay(track),\n        masterGain: this.masterGain\n      }));\n    });\n    this.lastPlay = currentTime; // use these to track when the playlist has fully stopped.\n\n    this.playoutPromises = playoutPromises;\n    this.startAnimation(start);\n    return Promise.all(this.playoutPromises);\n  }\n\n  pause() {\n    if (!this.isPlaying()) {\n      return Promise.all(this.playoutPromises);\n    }\n\n    this.pausedAt = this.getCurrentTime();\n    return this.playbackReset();\n  }\n\n  stop() {\n    if (this.mediaRecorder && this.mediaRecorder.state === \"recording\") {\n      this.mediaRecorder.stop();\n    }\n\n    this.pausedAt = undefined;\n    this.playbackSeconds = 0;\n    return this.playbackReset();\n  }\n\n  playbackReset() {\n    this.lastSeeked = undefined;\n    this.stopAnimation();\n    this.tracks.forEach(track => {\n      track.scheduleStop();\n      track.setState(this.getState());\n    });\n    this.drawRequest();\n    return Promise.all(this.playoutPromises);\n  }\n\n  rewind() {\n    return this.stop().then(() => {\n      this.scrollLeft = 0;\n      this.ee.emit(\"select\", 0, 0);\n    });\n  }\n\n  fastForward() {\n    return this.stop().then(() => {\n      if (this.viewDuration < this.duration) {\n        this.scrollLeft = this.duration - this.viewDuration;\n      } else {\n        this.scrollLeft = 0;\n      }\n\n      this.ee.emit(\"select\", this.duration, this.duration);\n    });\n  }\n\n  clear() {\n    return this.stop().then(() => {\n      this.tracks = [];\n      this.soloedTracks = [];\n      this.mutedTracks = [];\n      this.playoutPromises = [];\n      this.cursor = 0;\n      this.playbackSeconds = 0;\n      this.duration = 0;\n      this.scrollLeft = 0;\n      this.seek(0, 0, undefined);\n    });\n  }\n\n  record() {\n    const playoutPromises = [];\n    this.mediaRecorder.start(300);\n    this.tracks.forEach(track => {\n      track.setState(\"none\");\n      playoutPromises.push(track.schedulePlay(this.ac.currentTime, 0, undefined, {\n        shouldPlay: this.shouldTrackPlay(track)\n      }));\n    });\n    this.playoutPromises = playoutPromises;\n  }\n\n  startAnimation(startTime) {\n    this.lastDraw = this.ac.currentTime;\n    this.animationRequest = window.requestAnimationFrame(() => {\n      this.updateEditor(startTime);\n    });\n  }\n\n  stopAnimation() {\n    window.cancelAnimationFrame(this.animationRequest);\n    this.lastDraw = undefined;\n  }\n\n  seek(start, end, track) {\n    if (this.isPlaying()) {\n      this.lastSeeked = start;\n      this.pausedAt = undefined;\n      this.restartPlayFrom(start);\n    } else {\n      // reset if it was paused.\n      this.setActiveTrack(track || this.tracks[0]);\n      this.pausedAt = start;\n      this.setTimeSelection(start, end);\n\n      if (this.getSeekStyle() === \"fill\") {\n        this.playbackSeconds = start;\n      }\n    }\n  }\n  /*\n   * Animation function for the playlist.\n   * Keep under 16.7 milliseconds based on a typical screen refresh rate of 60fps.\n   */\n\n\n  updateEditor(cursor) {\n    const currentTime = this.ac.currentTime;\n    const selection = this.getTimeSelection();\n    const cursorPos = cursor || this.cursor;\n    const elapsed = currentTime - this.lastDraw;\n\n    if (this.isPlaying()) {\n      const playbackSeconds = cursorPos + elapsed;\n      this.ee.emit(\"timeupdate\", playbackSeconds);\n      this.animationRequest = window.requestAnimationFrame(() => {\n        this.updateEditor(playbackSeconds);\n      });\n      this.playbackSeconds = playbackSeconds;\n      this.draw(this.render());\n      this.lastDraw = currentTime;\n    } else {\n      if (cursorPos + elapsed >= (this.isSegmentSelection() ? selection.end : this.duration)) {\n        this.ee.emit(\"finished\");\n      }\n\n      this.stopAnimation();\n      this.resetDrawTimer = setTimeout(() => {\n        this.pausedAt = undefined;\n        this.lastSeeked = undefined;\n        this.setState(this.getState());\n        this.playbackSeconds = 0;\n        this.draw(this.render());\n      }, 0);\n    }\n  }\n\n  drawRequest() {\n    window.requestAnimationFrame(() => {\n      this.draw(this.render());\n    });\n  }\n\n  draw(newTree) {\n    const patches = diff(this.tree, newTree);\n    this.rootNode = patch(this.rootNode, patches);\n    this.tree = newTree; // use for fast forwarding.\n\n    this.viewDuration = pixelsToSeconds(this.rootNode.clientWidth - this.controls.width, this.samplesPerPixel, this.sampleRate);\n  }\n\n  getTrackRenderData(data = {}) {\n    const defaults = {\n      height: this.waveHeight,\n      resolution: this.samplesPerPixel,\n      sampleRate: this.sampleRate,\n      controls: this.controls,\n      isActive: false,\n      timeSelection: this.getTimeSelection(),\n      playlistLength: this.duration,\n      playbackSeconds: this.playbackSeconds,\n      colors: this.colors,\n      barWidth: this.barWidth,\n      barGap: this.barGap\n    };\n    return _defaults({}, data, defaults);\n  }\n\n  isActiveTrack(track) {\n    const activeTrack = this.getActiveTrack();\n\n    if (this.isSegmentSelection()) {\n      return activeTrack === track;\n    }\n\n    return true;\n  }\n\n  renderAnnotations() {\n    return this.annotationList.render();\n  }\n\n  renderTimeScale() {\n    const controlWidth = this.controls.show ? this.controls.width : 0;\n    const timeScale = new TimeScale(this.duration, this.scrollLeft, this.samplesPerPixel, this.sampleRate, controlWidth, this.colors);\n    return timeScale.render();\n  }\n\n  renderTrackSection() {\n    const trackElements = this.tracks.map(track => {\n      const collapsed = this.collapsedTracks.indexOf(track) > -1;\n      return track.render(this.getTrackRenderData({\n        isActive: this.isActiveTrack(track),\n        shouldPlay: this.shouldTrackPlay(track),\n        soloed: this.soloedTracks.indexOf(track) > -1,\n        muted: this.mutedTracks.indexOf(track) > -1,\n        collapsed,\n        height: collapsed ? this.collapsedWaveHeight : this.waveHeight,\n        barGap: this.barGap,\n        barWidth: this.barWidth\n      }));\n    });\n    return h(\"div.playlist-tracks\", {\n      attributes: {\n        style: \"overflow: auto;\"\n      },\n      onscroll: e => {\n        this.scrollLeft = pixelsToSeconds(e.target.scrollLeft, this.samplesPerPixel, this.sampleRate);\n        this.ee.emit(\"scroll\");\n      },\n      hook: new ScrollHook(this)\n    }, trackElements);\n  }\n\n  render() {\n    const containerChildren = [];\n\n    if (this.showTimescale) {\n      containerChildren.push(this.renderTimeScale());\n    }\n\n    containerChildren.push(this.renderTrackSection());\n\n    if (this.annotationList.length) {\n      containerChildren.push(this.renderAnnotations());\n    }\n\n    return h(\"div.playlist\", {\n      attributes: {\n        style: \"overflow: hidden; position: relative;\"\n      }\n    }, containerChildren);\n  }\n\n  getInfo() {\n    const info = [];\n    this.tracks.forEach(track => {\n      info.push(track.getTrackDetails());\n    });\n    return info;\n  }\n\n}","map":null,"metadata":{},"sourceType":"module"}